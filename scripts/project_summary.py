#!/usr/bin/env python3
"""
Project Completion Summary Script
Validates all components of the Sales Analytics Dashboard project
"""

import os
import pandas as pd
import sqlite3
from pathlib import Path
import sys

def print_header(title):
    """Print a formatted header"""
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}")

def check_file_exists(filepath, description):
    """Check if a file exists and print status"""
    exists = os.path.exists(filepath)
    status = "âœ… EXISTS" if exists else "âŒ MISSING"
    print(f"{status}: {description}")
    return exists

def check_data_pipeline():
    """Check the data pipeline components"""
    print_header("ðŸ“Š DATA PIPELINE VALIDATION")
    
    # Check data files
    data_files = {
        'data/sales_data.csv': 'Raw sales data (generated)',
        'data/clean_sales_data.csv': 'Cleaned sales data',
        'data/sales.db': 'SQLite database'
    }
    
    all_data_exists = True
    for filepath, description in data_files.items():
        if not check_file_exists(filepath, description):
            all_data_exists = False
    
    # Check data content
    if all_data_exists:
        try:
            df = pd.read_csv('data/clean_sales_data.csv')
            print(f"âœ… Data loaded successfully: {len(df):,} records")
            
            # Check database
            conn = sqlite3.connect('data/sales.db')
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM sales")
            db_count = cursor.fetchone()[0]
            conn.close()
            print(f"âœ… Database verified: {db_count:,} records in SQLite")
            
            # Basic data validation
            required_columns = ['date', 'product', 'region', 'total_sales', 'quantity', 'unit_price']
            missing_cols = [col for col in required_columns if col not in df.columns]
            
            if not missing_cols:
                print("âœ… All required columns present")
                
                # Data quality checks
                revenue = df['total_sales'].sum()
                print(f"âœ… Total revenue: ${revenue:,.0f}")
                
                date_range = f"{df['date'].min()} to {df['date'].max()}"
                print(f"âœ… Date range: {date_range}")
                
                products = df['product'].nunique()
                regions = df['region'].nunique()
                print(f"âœ… Data diversity: {products} products, {regions} regions")
            else:
                print(f"âŒ Missing columns: {missing_cols}")
                
        except Exception as e:
            print(f"âŒ Data validation error: {str(e)}")
    
    return all_data_exists

def check_scripts():
    """Check all Python scripts"""
    print_header("ðŸ”§ SCRIPTS VALIDATION")
    
    scripts = {
        'scripts/generate_data.py': 'Data generation script',
        'scripts/clean_data.py': 'Data cleaning script',
        'scripts/load_to_sql.py': 'Database loading script',
        'scripts/utils.py': 'Utility functions',
        'scripts/streamlit_dashboard.py': 'Streamlit dashboard'
    }
    
    all_scripts_exist = True
    for script, description in scripts.items():
        if not check_file_exists(script, description):
            all_scripts_exist = False
    
    return all_scripts_exist

def check_notebooks():
    """Check Jupyter notebooks"""
    print_header("ðŸ““ NOTEBOOKS VALIDATION")
    
    notebooks = {
        'notebooks/EDA.ipynb': 'Exploratory Data Analysis notebook'
    }
    
    all_notebooks_exist = True
    for notebook, description in notebooks.items():
        if not check_file_exists(notebook, description):
            all_notebooks_exist = False
    
    return all_notebooks_exist

def check_powerbi_guides():
    """Check Power BI documentation"""
    print_header("ðŸ“Š POWER BI DOCUMENTATION")
    
    powerbi_files = {
        'powerbi/PowerBI_Setup_Guide.md': 'Power BI setup guide',
        'powerbi/DAX_Measures.txt': 'DAX measures and formulas',
        'powerbi/Dashboard_Layout.md': 'Dashboard layout guide',
        'powerbi/Dashboard_Checklist.md': 'Validation checklist'
    }
    
    all_powerbi_exists = True
    for filepath, description in powerbi_files.items():
        if not check_file_exists(filepath, description):
            all_powerbi_exists = False
    
    return all_powerbi_exists

def check_reports():
    """Check reports and insights"""
    print_header("ðŸ“ˆ REPORTS AND INSIGHTS")
    
    reports = {
        'reports/insights.md': 'Data insights and recommendations'
    }
    
    all_reports_exist = True
    for report, description in reports.items():
        if not check_file_exists(report, description):
            all_reports_exist = False
    
    return all_reports_exist

def check_assets():
    """Check assets and screenshots"""
    print_header("ðŸ“¸ ASSETS AND SCREENSHOTS")
    
    assets_dir = 'assets/screenshots'
    if os.path.exists(assets_dir):
        print(f"âœ… EXISTS: Screenshots directory")
        
        # List screenshot files
        screenshots = list(Path(assets_dir).glob('*.png')) + list(Path(assets_dir).glob('*.html'))
        if screenshots:
            print(f"âœ… Found {len(screenshots)} screenshot/export files:")
            for screenshot in sorted(screenshots):
                print(f"   - {screenshot.name}")
        else:
            print("âš ï¸  No screenshot files found")
            return False
    else:
        print(f"âŒ MISSING: Screenshots directory")
        return False
    
    return True

def check_configuration():
    """Check configuration files"""
    print_header("âš™ï¸ CONFIGURATION FILES")
    
    config_files = {
        'requirements.txt': 'Python dependencies',
        '.gitignore': 'Git ignore rules',
        'README.md': 'Project documentation'
    }
    
    all_config_exists = True
    for config, description in config_files.items():
        if not check_file_exists(config, description):
            all_config_exists = False
    
    # Check requirements.txt content
    if os.path.exists('requirements.txt'):
        with open('requirements.txt', 'r') as f:
            requirements = f.read().strip().split('\n')
            required_packages = ['pandas', 'numpy', 'plotly', 'streamlit', 'dash']
            missing_packages = [pkg for pkg in required_packages if not any(pkg in req for req in requirements)]
            
            if not missing_packages:
                print("âœ… All required packages in requirements.txt")
            else:
                print(f"âš ï¸  Missing packages in requirements.txt: {missing_packages}")
    
    return all_config_exists

def run_dashboard_tests():
    """Test dashboard functionality"""
    print_header("ðŸš€ DASHBOARD FUNCTIONALITY TESTS")
    
    try:
        # Test data loading capability
        import pandas as pd
        df = pd.read_csv('data/clean_sales_data.csv')
        print("âœ… Data loading: Successful")
        
        # Test basic visualizations
        import matplotlib.pyplot as plt
        import seaborn as sns
        plt.style.use('default')
        print("âœ… Matplotlib/Seaborn: Available")
        
        # Test Plotly
        import plotly.express as px
        import plotly.graph_objects as go
        print("âœ… Plotly: Available")
        
        # Test Streamlit (import only)
        import streamlit as st
        print("âœ… Streamlit: Available")
        
        print("âœ… All dashboard libraries are functional")
        
    except ImportError as e:
        print(f"âŒ Import error: {str(e)}")
        return False
    except Exception as e:
        print(f"âŒ Test error: {str(e)}")
        return False
    
    return True

def print_project_summary():
    """Print final project summary"""
    print_header("ðŸ“‹ PROJECT COMPLETION SUMMARY")
    
    print("ðŸŽ¯ COMPLETED COMPONENTS:")
    print("   âœ… Data Pipeline (Generate â†’ Clean â†’ Load)")
    print("   âœ… Exploratory Data Analysis (EDA)")
    print("   âœ… SQLite Database Integration")
    print("   âœ… Interactive Streamlit Dashboard")
    print("   âœ… Comprehensive Documentation")
    print("   âœ… Data Insights and Recommendations")
    print()
    
    print("ðŸš€ AVAILABLE DASHBOARD:")
    print("   ðŸ“Š Streamlit Dashboard: streamlit run scripts/streamlit_dashboard.py --server.port=8051")
    print()
    
    print("ðŸ”— ACCESS POINT:")
    print("   ðŸŒ Streamlit: http://localhost:8051")
    print()
    
    print("ðŸ“ˆ KEY INSIGHTS (Sample Data):")
    try:
        df = pd.read_csv('data/clean_sales_data.csv')
        total_revenue = df['total_sales'].sum()
        total_transactions = len(df)
        avg_order = df['total_sales'].mean()
        
        print(f"   ðŸ’° Total Revenue: ${total_revenue:,.0f}")
        print(f"   ðŸ“‹ Transactions: {total_transactions:,}")
        print(f"   ðŸ“Š Avg Order Value: ${avg_order:.0f}")
        
        # Top product
        top_product = df.groupby('product')['total_sales'].sum().sort_values(ascending=False)
        print(f"   ðŸ† Top Product: {top_product.index[0]} (${top_product.iloc[0]:,.0f})")
        
        # Top region
        top_region = df.groupby('region')['total_sales'].sum().sort_values(ascending=False)
        print(f"   ðŸŒ Top Region: {top_region.index[0]} (${top_region.iloc[0]:,.0f})")
        
    except:
        print("   âš ï¸  Unable to load sample insights")

def main():
    """Main validation and summary function"""
    print("ðŸ” SALES ANALYTICS DASHBOARD - PROJECT VALIDATION")
    print("=" * 60)
    
    # Run all validation checks
    checks = [
        check_data_pipeline(),
        check_scripts(),
        check_notebooks(),
        check_powerbi_guides(),
        check_reports(),
        check_assets(),
        check_configuration(),
        run_dashboard_tests()
    ]
    
    # Calculate success rate
    success_rate = (sum(checks) / len(checks)) * 100
    
    print_header("ðŸŽ¯ VALIDATION RESULTS")
    print(f"Overall Project Completion: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print("ðŸŽ‰ PROJECT COMPLETE - Ready for portfolio presentation!")
    elif success_rate >= 75:
        print("âš ï¸  PROJECT MOSTLY COMPLETE - Minor issues to address")
    else:
        print("âŒ PROJECT INCOMPLETE - Major components missing")
    
    # Print project summary
    print_project_summary()
    
    return success_rate >= 90

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
